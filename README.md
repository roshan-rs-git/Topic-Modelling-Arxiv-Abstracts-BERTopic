# ğŸ“š Topic Modelling ArXiv Abstracts Using BERTopic

This project analyzes 2.7M arXiv research papers by clustering their abstracts using BERTopic to uncover hidden thematic trends, while leveraging categories as labels for validation. The goal is to map the evolution of scientific topics and identify interdisciplinary connections in large-scale academic literature.

## ğŸš€ Overview

We utilize **BERTopic**, which integrates Transformer-based sentence embeddings, dimensionality reduction (UMAP), density-based clustering (HDBSCAN), and modern topic representation models (GPT-4o-mini, KeyBERT, and MMR) to produce interpretable and scalable topic models.

This project was built as part of our final submission for CS 5660: Advanced Artificial Intelligence.

## ğŸ“Š Results

Our model identified 121 distinct topics from the ArXiv abstracts with the following metrics:
- **Number of topics found**: 121
- **Documents per topic (avg)**: 455.5
- **Topic diversity score**: 0.7322 (higher is better)

### Top 5 largest topics:
- **Topic 0** (Count: 6818): image, to, learning, and, our, methods, on, data, training, performance
- **Topic 1** (Count: 5824): spin, magnetic, temperature, the, phase, in, graphene, electron, of, electronic
- **Topic 2** (Count: 1437): robot, policy, learning, reinforcement, rl, robots, control, agent, tasks, planning
- **Topic 3** (Count: 1326): graphs, graph, vertices, vertex, edge, number, edges, every, if, coloring

Topic size distribution: min=100, max=6818, ratio=0.0147

## âœ¨ Key Features

- ğŸ§  Semantic embeddings with `BAAI/bge-small-en` via SentenceTransformers
- ğŸ“‰ UMAP for dimensionality reduction
- ğŸ“Œ HDBSCAN for unsupervised clustering (no need to pre-define number of topics)
- ğŸ§¾ Topic labeling using:
  - GPT-4o-mini (via OpenAI API)
  - KeyBERT + Maximal Marginal Relevance (MMR)
- ğŸ“Š Visualizations of topic clusters and top keywords
- ğŸ“ˆ Scalable to millions of documents

## ğŸ§° Tech Stack

| Tool / Library        | Purpose                            |
|-----------------------|-------------------------------------|
| Python 3.10           | Programming language                |
| SentenceTransformers  | Generating document embeddings      |
| UMAP                  | Dimensionality reduction            |
| HDBSCAN               | Density-based clustering            |
| BERTopic              | Topic modeling pipeline             |
| OpenAI API (GPT-4o)   | High-quality topic labeling         |
| KeyBERT + MMR         | Keyword extraction                  |
| Pandas / Numpy        | Data wrangling and stats            |
| Matplotlib / Plotly   | Visualization                       |

## ğŸ“‚ Repository Structure

```bash
â”œâ”€â”€ dataset/                          # Data directory
â”‚   â”œâ”€â”€ preprocessed/                 # Preprocessed datasets
â”‚   â”‚   â””â”€â”€ arxiv_processed_100000.csv
â”‚   â””â”€â”€ raw/sample/                   # Raw and sampled data
â”‚       â””â”€â”€ arxiv_sampled_dataset.json
â”œâ”€â”€ notebooks/                        # Jupyter notebooks
â”‚   â”œâ”€â”€ Data_Cleaning/                # Data preprocessing
â”‚   â”‚   â””â”€â”€ Arxiv_datacleaning.ipynb
â”‚   â”œâ”€â”€ Model_Building_Final/         # Model implementation
â”‚   â”‚   â””â”€â”€ Arxiv_BERTopic_Modelling_100,000samples.ipynb
â”‚   â””â”€â”€ visualizations/               # Results visualization
â”‚       â””â”€â”€ Arxiv_Data_Visualizations.ipynb
â”œâ”€â”€ README.md                         # Project documentation
â””â”€â”€ requirements.txt                  # Environment dependencies
```

## ğŸ› ï¸ Getting Started

### Prerequisites
- Python 3.10 or higher
- Pip package manager

### Installation

1. Clone the repository
```bash
git clone https://github.com/yourusername/arxiv-topic-modeling.git
cd arxiv-topic-modeling
```

2. Install required packages
```bash
pip install -r requirements.txt
```

3. Run the notebooks in the following order:
   - First, data cleaning: `notebooks/Data_Cleaning/Arxiv_datacleaning.ipynb`
   - Then, model building: `notebooks/Model_Building_Final/Arxiv_BERTopic_Modelling_100,000samples.ipynb`
   - Finally, visualizations: `notebooks/visualizations/Arxiv_Data_Visualizations.ipynb`


## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome! Feel free to check the [issues page](https://github.com/yourusername/arxiv-topic-modeling/issues).

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.
